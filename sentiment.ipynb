{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of free-text comments using NLTK\n",
    "\n",
    "2015-07-04 -- by [Harald Schilly](http://harald.schil.ly) -- License: Apache 2.0\n",
    "\n",
    "The following NLTK demo works for German free-text comments.\n",
    "It tokenizes the text, cleans it up, does word stemming and then trains a naive bayesian model.\n",
    "In the end, a few tests show that it did indeed learn something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from codecs import open\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of tokenizer and stemmer\n",
    "\n",
    "... just the defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NLTK tokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "# NLTK stemmer for german\n",
    "from nltk.stem.snowball import GermanStemmer\n",
    "stemmer_de = GermanStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "\n",
    "For the demo, a map of categories to a list of texts is read from a data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative: 16 entries\n",
      "positive: 14 entries\n",
      "question: 7 entries\n"
     ]
    }
   ],
   "source": [
    "data = yaml.load(open(\"reviews1.yaml\", \"r\", \"utf-8\"))\n",
    "for cat, texts in data.items():\n",
    "    print(\"%s: %d entries\" % (cat, len(texts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing texts in `data`\n",
    "\n",
    "`data2` is then a map of categories to a list of tokenized texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each text, this tokenizing and stemming process is applied\n",
    "def process_text(text):\n",
    "    words = tokenizer.tokenize(text)\n",
    "    words = [stemmer_de.stem(w) for w in words if len(w) >= 3]\n",
    "    words = [(\"<QM>\" if '?' in w else w) for w in words]\n",
    "    return words\n",
    "\n",
    "data2 = {}\n",
    "for cat, texts in data.items():\n",
    "    data2[cat] = []\n",
    "    for text in texts:\n",
    "        data2[cat].append(process_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for texts in data2.values():\n",
    "    [all_words.extend(text) for text in texts]\n",
    "\n",
    "wordlist = nltk.FreqDist(all_words)\n",
    "word_features = wordlist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('und', 16),\n",
       " ('ein', 11),\n",
       " ('das', 9),\n",
       " ('bei', 6),\n",
       " ('nicht', 6),\n",
       " ('ist', 6),\n",
       " ('euch', 5),\n",
       " ('noch', 5),\n",
       " ('ich', 5),\n",
       " ('wied', 4)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 most common words\n",
    "wordlist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(doc):\n",
    "    doc_words = set(doc)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[\"contains %s\" % word] = (word in doc_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set & Bayes Classifier\n",
    "\n",
    "NTLK's NaiveBayesClassifier is trained using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# just a little helper\n",
    "def get_all_docs():\n",
    "    for cat, texts in data2.items():\n",
    "        for words in texts:\n",
    "            yield (words, cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, list(get_all_docs()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is where the magic happens:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list of most informative features is an indicator if the training did work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "           contains auch = True           questi : negati =      3.5 : 1.0\n",
      "            contains ist = True           negati : positi =      2.6 : 1.0\n",
      "           contains wied = True           positi : negati =      2.6 : 1.0\n",
      "            contains der = True           positi : negati =      2.6 : 1.0\n",
      "           contains mein = True           positi : negati =      2.6 : 1.0\n",
      "           contains euch = True           positi : negati =      2.6 : 1.0\n",
      "            contains ihr = True           questi : negati =      2.1 : 1.0\n",
      "           contains bitt = True           questi : negati =      2.1 : 1.0\n",
      "           contains viel = True           questi : negati =      2.1 : 1.0\n",
      "            contains ich = True           negati : positi =      2.1 : 1.0\n",
      "            contains und = True           positi : questi =      2.0 : 1.0\n",
      "            contains imm = True           positi : negati =      1.9 : 1.0\n",
      "           contains aber = True           positi : negati =      1.9 : 1.0\n",
      "            contains auf = True           positi : negati =      1.9 : 1.0\n",
      "           contains gibt = True           questi : positi =      1.9 : 1.0\n",
      "            contains das = True           negati : questi =      1.7 : 1.0\n",
      "           contains morg = False          negati : questi =      1.7 : 1.0\n",
      "            contains ein = True           negati : positi =      1.6 : 1.0\n",
      "          contains nicht = False          positi : negati =      1.6 : 1.0\n",
      "            contains fur = True           negati : positi =      1.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = \"diese art von bedienung brauchen wir gar nicht.\"\n",
    "classifier.classify(extract_features(process_text(t1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = \"Hervorragende Bedienung, jederzeit gerne wieder!\"\n",
    "classifier.classify(extract_features(process_text(t2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = \"Ganz schlechtes Service, kann ich nicht empfehlen ...\"\n",
    "classifier.classify(extract_features(process_text(t3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4 = \"Wir kommen gerne jederzeit wieder.\"\n",
    "classifier.classify(extract_features(process_text(t4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5 = \"uns hat es sehr gut gefallen\"\n",
    "classifier.classify(extract_features(process_text(t5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t6 = \"Wann sperrt ihr morgen auf?\"\n",
    "classifier.classify(extract_features(process_text(t6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All probabilities\n",
    "\n",
    "List all probabilities for each testing text. Gives an impression how well the classification did work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def all_probabilities(text):\n",
    "    from math import exp\n",
    "    print(text)\n",
    "    probs = classifier.prob_classify(extract_features(process_text(text)))\n",
    "    for label, lprop in probs._prob_dict.items():\n",
    "        print(\"%5.1f%% %s\" % (100. * exp(lprop), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diese art von bedienung brauchen wir gar nicht.\n",
      " 66.2% negative\n",
      "  9.4% positive\n",
      "  1.5% question\n"
     ]
    }
   ],
   "source": [
    "all_probabilities(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hervorragende Bedienung, jederzeit gerne wieder!\n",
      " 12.9% negative\n",
      " 64.7% positive\n",
      "  0.3% question\n"
     ]
    }
   ],
   "source": [
    "all_probabilities(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganz schlechtes Service, kann ich nicht empfehlen ...\n",
      " 99.1% negative\n",
      "  0.0% positive\n",
      "  0.0% question\n"
     ]
    }
   ],
   "source": [
    "all_probabilities(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wir kommen gerne jederzeit wieder.\n",
      "  0.0% negative\n",
      " 99.4% positive\n",
      "  0.0% question\n"
     ]
    }
   ],
   "source": [
    "all_probabilities(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uns hat es sehr gut gefallen\n",
      "  7.9% negative\n",
      " 73.5% positive\n",
      "  0.4% question\n"
     ]
    }
   ],
   "source": [
    "all_probabilities(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wann sperrt ihr morgen auf?\n",
      "  0.1% negative\n",
      "  2.9% positive\n",
      " 86.9% question\n"
     ]
    }
   ],
   "source": [
    "all_probabilities(t6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
